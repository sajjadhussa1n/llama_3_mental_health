{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import TrainingArguments\nfrom transformers import Trainer\nimport pandas as pd\nimport datasets\nfrom transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:27:19.460847Z","iopub.execute_input":"2024-11-26T18:27:19.461704Z","iopub.status.idle":"2024-11-26T18:27:37.028694Z","shell.execute_reply.started":"2024-11-26T18:27:19.461642Z","shell.execute_reply":"2024-11-26T18:27:37.028023Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:27:41.953642Z","iopub.execute_input":"2024-11-26T18:27:41.954543Z","iopub.status.idle":"2024-11-26T18:27:42.084059Z","shell.execute_reply.started":"2024-11-26T18:27:41.954505Z","shell.execute_reply":"2024-11-26T18:27:42.083178Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")\ntokenizer  = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:27:49.990937Z","iopub.execute_input":"2024-11-26T18:27:49.991777Z","iopub.status.idle":"2024-11-26T18:28:53.415421Z","shell.execute_reply.started":"2024-11-26T18:27:49.991727Z","shell.execute_reply":"2024-11-26T18:28:53.414664Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67adbe69bb4742e78bc8c7080c04dcbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec7e5eba142f4713ab2f7987f6c8e05f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce3d3d537b5849c98799549c3b12ccdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e72f72c587b435b95857edf26cb667c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cb158305bad4411b058efd3c31bc183"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce209c4d40f24004aedeecada6be95b9"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"ds = load_dataset(\"marmikpandya/mental-health\")\nprint(ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:29:01.518889Z","iopub.execute_input":"2024-11-26T18:29:01.519546Z","iopub.status.idle":"2024-11-26T18:29:03.974110Z","shell.execute_reply.started":"2024-11-26T18:29:01.519511Z","shell.execute_reply":"2024-11-26T18:29:03.973284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"data.jsonl:   0%|          | 0.00/10.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51a50ba54dd842b289e911a19969bca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/13358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12908f734c5549909232b34db732bf49"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'output', 'input'],\n        num_rows: 13358\n    })\n})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"processed_ds = []\nfor i in range(len(ds['train'])):\n  question = ds['train']['input'][i]\n  answer = ds['train']['output'][i]\n  processed_ds.append({'question': question, 'answer': answer})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:29:14.288283Z","iopub.execute_input":"2024-11-26T18:29:14.288599Z","iopub.status.idle":"2024-11-26T18:34:24.097471Z","shell.execute_reply.started":"2024-11-26T18:29:14.288572Z","shell.execute_reply":"2024-11-26T18:34:24.096534Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenized_dataset = datasets.Dataset.from_list(processed_ds)\nprint(tokenized_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:36:29.976291Z","iopub.execute_input":"2024-11-26T18:36:29.977109Z","iopub.status.idle":"2024-11-26T18:36:30.048963Z","shell.execute_reply.started":"2024-11-26T18:36:29.977073Z","shell.execute_reply":"2024-11-26T18:36:30.047966Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['question', 'answer'],\n    num_rows: 13358\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"device = torch.device('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:36:39.494032Z","iopub.execute_input":"2024-11-26T18:36:39.494397Z","iopub.status.idle":"2024-11-26T18:36:39.498971Z","shell.execute_reply.started":"2024-11-26T18:36:39.494364Z","shell.execute_reply":"2024-11-26T18:36:39.497981Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:36:46.929170Z","iopub.execute_input":"2024-11-26T18:36:46.929524Z","iopub.status.idle":"2024-11-26T18:36:48.641267Z","shell.execute_reply.started":"2024-11-26T18:36:46.929493Z","shell.execute_reply":"2024-11-26T18:36:48.640410Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 2048)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def tokenize_func(examples):\n  if examples['question'] and examples['answer']:\n    text = examples['question'][0] + examples['answer'][0]\n    tokenized_examples = tokenizer(text, padding = True, truncation = True, max_length = 1024, return_tensors = 'pt')\n    return tokenized_examples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:37:13.241497Z","iopub.execute_input":"2024-11-26T18:37:13.241848Z","iopub.status.idle":"2024-11-26T18:37:13.246768Z","shell.execute_reply.started":"2024-11-26T18:37:13.241816Z","shell.execute_reply":"2024-11-26T18:37:13.245914Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.map(tokenize_func, batched = True, batch_size = 1, drop_last_batch = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:37:22.004996Z","iopub.execute_input":"2024-11-26T18:37:22.005359Z","iopub.status.idle":"2024-11-26T18:37:40.966468Z","shell.execute_reply.started":"2024-11-26T18:37:22.005326Z","shell.execute_reply":"2024-11-26T18:37:40.965576Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"648580902fb948ec8392262d798a0021"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.add_column('labels', tokenized_dataset['input_ids'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:37:46.357529Z","iopub.execute_input":"2024-11-26T18:37:46.357847Z","iopub.status.idle":"2024-11-26T18:37:50.778867Z","shell.execute_reply.started":"2024-11-26T18:37:46.357819Z","shell.execute_reply":"2024-11-26T18:37:50.777914Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"tokenized_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:39:04.071069Z","iopub.execute_input":"2024-11-26T18:39:04.071995Z","iopub.status.idle":"2024-11-26T18:39:04.080581Z","shell.execute_reply.started":"2024-11-26T18:39:04.071942Z","shell.execute_reply":"2024-11-26T18:39:04.079589Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'question': \"I'm feeling really anxious lately and I don't know why.\",\n 'answer': \"It's common to feel anxious at times, and there can be many reasons for it. Have there been any recent changes or stressors in your life that may be contributing to your anxiety? Let's work together to identify any triggers and develop coping strategies to manage your anxiety.\",\n 'input_ids': [128000,\n  40,\n  2846,\n  8430,\n  2216,\n  38100,\n  31445,\n  323,\n  358,\n  1541,\n  956,\n  1440,\n  3249,\n  28628,\n  596,\n  4279,\n  311,\n  2733,\n  38100,\n  520,\n  3115,\n  11,\n  323,\n  1070,\n  649,\n  387,\n  1690,\n  8125,\n  369,\n  433,\n  13,\n  12522,\n  1070,\n  1027,\n  904,\n  3293,\n  4442,\n  477,\n  8631,\n  1105,\n  304,\n  701,\n  2324,\n  430,\n  1253,\n  387,\n  29820,\n  311,\n  701,\n  18547,\n  30,\n  6914,\n  596,\n  990,\n  3871,\n  311,\n  10765,\n  904,\n  31854,\n  323,\n  2274,\n  63082,\n  15174,\n  311,\n  10299,\n  701,\n  18547,\n  13],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'labels': [128000,\n  40,\n  2846,\n  8430,\n  2216,\n  38100,\n  31445,\n  323,\n  358,\n  1541,\n  956,\n  1440,\n  3249,\n  28628,\n  596,\n  4279,\n  311,\n  2733,\n  38100,\n  520,\n  3115,\n  11,\n  323,\n  1070,\n  649,\n  387,\n  1690,\n  8125,\n  369,\n  433,\n  13,\n  12522,\n  1070,\n  1027,\n  904,\n  3293,\n  4442,\n  477,\n  8631,\n  1105,\n  304,\n  701,\n  2324,\n  430,\n  1253,\n  387,\n  29820,\n  311,\n  701,\n  18547,\n  30,\n  6914,\n  596,\n  990,\n  3871,\n  311,\n  10765,\n  904,\n  31854,\n  323,\n  2274,\n  63082,\n  15174,\n  311,\n  10299,\n  701,\n  18547,\n  13]}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"split_dataset = tokenized_dataset.train_test_split(test_size = 0.2, shuffle = True, seed = 42)\ntrain_dataset = split_dataset['train']\ntest_dataset = split_dataset['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:39:18.064872Z","iopub.execute_input":"2024-11-26T18:39:18.065213Z","iopub.status.idle":"2024-11-26T18:39:18.177438Z","shell.execute_reply.started":"2024-11-26T18:39:18.065180Z","shell.execute_reply":"2024-11-26T18:39:18.176494Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import os\nout_dir = './kaggle/working/LLM_Mental_Health'\nmodel_name = 'llama-3.2-1b-mental-health'\noutput_dir = os.path.join(out_dir, model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:39:27.865136Z","iopub.execute_input":"2024-11-26T18:39:27.865506Z","iopub.status.idle":"2024-11-26T18:39:27.869980Z","shell.execute_reply.started":"2024-11-26T18:39:27.865474Z","shell.execute_reply":"2024-11-26T18:39:27.869053Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"training_args = TrainingArguments(\n\n  # Learning rate\n  learning_rate=3.0e-5,\n\n  # Number of training epochs\n  num_train_epochs=1,\n\n  # Max steps to train for (each step is a batch of data)\n  # Overrides num_train_epochs, if not -1\n  max_steps=-1,\n\n  # Batch size for training\n  per_device_train_batch_size=1,\n\n  # Directory to save model checkpoints\n  output_dir=output_dir,\n\n  # Other arguments\n  overwrite_output_dir=False, # Overwrite the content of the output directory\n  disable_tqdm=False, # Disable progress bars\n  eval_steps=120, # Number of update steps between two evaluations\n  save_steps=120, # After # steps model is saved\n  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n  per_device_eval_batch_size=1, # Batch size for evaluation\n  evaluation_strategy=\"steps\",\n  logging_strategy=\"steps\",\n  logging_steps=1,\n  optim=\"adafactor\",\n  gradient_accumulation_steps = 4,\n  gradient_checkpointing=False,\n\n  # Parameters for early stopping\n  load_best_model_at_end=True,\n  save_total_limit=1,\n  metric_for_best_model=\"eval_loss\",\n  greater_is_better=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:39:41.182064Z","iopub.execute_input":"2024-11-26T18:39:41.182412Z","iopub.status.idle":"2024-11-26T18:39:41.215101Z","shell.execute_reply.started":"2024-11-26T18:39:41.182379Z","shell.execute_reply":"2024-11-26T18:39:41.214254Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"trainer = Trainer(\n  model=model,\n  args=training_args,\n  train_dataset=train_dataset,\n  eval_dataset=test_dataset,\n  tokenizer = tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:39:54.560989Z","iopub.execute_input":"2024-11-26T18:39:54.561807Z","iopub.status.idle":"2024-11-26T18:39:55.270457Z","shell.execute_reply.started":"2024-11-26T18:39:54.561770Z","shell.execute_reply":"2024-11-26T18:39:55.269783Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T18:40:23.889608Z","iopub.execute_input":"2024-11-26T18:40:23.890488Z","iopub.status.idle":"2024-11-26T20:32:14.084956Z","shell.execute_reply.started":"2024-11-26T18:40:23.890449Z","shell.execute_reply":"2024-11-26T20:32:14.084053Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113768199998554, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a6815110903411aaf9bf3b6ba16991c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241126_184059-g3jmtb3n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sajjadhussain960-national-university-of-sciences-and-tec/huggingface/runs/g3jmtb3n' target=\"_blank\">./kaggle/working/LLM_Mental_Health/llama-3.2-1b-mental-health</a></strong> to <a href='https://wandb.ai/sajjadhussain960-national-university-of-sciences-and-tec/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sajjadhussain960-national-university-of-sciences-and-tec/huggingface' target=\"_blank\">https://wandb.ai/sajjadhussain960-national-university-of-sciences-and-tec/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sajjadhussain960-national-university-of-sciences-and-tec/huggingface/runs/g3jmtb3n' target=\"_blank\">https://wandb.ai/sajjadhussain960-national-university-of-sciences-and-tec/huggingface/runs/g3jmtb3n</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2671' max='2671' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2671/2671 1:51:09, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>120</td>\n      <td>1.937100</td>\n      <td>1.855947</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.456800</td>\n      <td>1.749454</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>2.110500</td>\n      <td>1.658997</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.878000</td>\n      <td>1.608170</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.427200</td>\n      <td>1.579676</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.880400</td>\n      <td>1.533818</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.925000</td>\n      <td>1.489371</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>1.425900</td>\n      <td>1.435812</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>1.229800</td>\n      <td>1.419371</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.042000</td>\n      <td>1.393061</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.850100</td>\n      <td>1.363106</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>1.060400</td>\n      <td>1.337649</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>1.851500</td>\n      <td>1.301008</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>2.692500</td>\n      <td>1.269243</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.927000</td>\n      <td>1.245571</td>\n    </tr>\n    <tr>\n      <td>1920</td>\n      <td>0.886500</td>\n      <td>1.227472</td>\n    </tr>\n    <tr>\n      <td>2040</td>\n      <td>1.504400</td>\n      <td>1.197211</td>\n    </tr>\n    <tr>\n      <td>2160</td>\n      <td>1.134600</td>\n      <td>1.177290</td>\n    </tr>\n    <tr>\n      <td>2280</td>\n      <td>1.898300</td>\n      <td>1.162452</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.866400</td>\n      <td>1.145319</td>\n    </tr>\n    <tr>\n      <td>2520</td>\n      <td>0.854700</td>\n      <td>1.132157</td>\n    </tr>\n    <tr>\n      <td>2640</td>\n      <td>0.809500</td>\n      <td>1.124777</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2671, training_loss=1.3851017801335848, metrics={'train_runtime': 6707.8276, 'train_samples_per_second': 1.593, 'train_steps_per_second': 0.398, 'total_flos': 7620878476787712.0, 'train_loss': 1.3851017801335848, 'epoch': 0.9998128392288976})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"save_dir = f'{output_dir}/finaltrainedv1'\ntrainer.save_model(save_dir)\nprint(\"Saved model to:\", save_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:32:39.426210Z","iopub.execute_input":"2024-11-26T20:32:39.426606Z","iopub.status.idle":"2024-11-26T20:32:53.762577Z","shell.execute_reply.started":"2024-11-26T20:32:39.426575Z","shell.execute_reply":"2024-11-26T20:32:53.761783Z"}},"outputs":[{"name":"stdout","text":"Saved model to: ./kaggle/working/LLM_Mental_Health/llama-3.2-1b-mental-health/finaltrainedv1\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"fine_tuned_model = AutoModelForCausalLM.from_pretrained(save_dir)\nfine_tuned_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:33:21.000366Z","iopub.execute_input":"2024-11-26T20:33:21.001008Z","iopub.status.idle":"2024-11-26T20:33:21.764105Z","shell.execute_reply.started":"2024-11-26T20:33:21.000972Z","shell.execute_reply":"2024-11-26T20:33:21.763142Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"fine_tuned_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:33:33.462990Z","iopub.execute_input":"2024-11-26T20:33:33.463821Z","iopub.status.idle":"2024-11-26T20:33:35.070659Z","shell.execute_reply.started":"2024-11-26T20:33:33.463785Z","shell.execute_reply":"2024-11-26T20:33:35.069824Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 2048)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"def truncate_to_nearest_sentence(text, max_output_tokens):\n    \"\"\"\n    Truncate the text to the last full stop before or at max_output_tokens.\n    \"\"\"\n    # Truncate the text to max_output_tokens\n    truncated_text = text[:max_output_tokens]\n    # Find the last full stop in the truncated text\n    last_full_stop = truncated_text.rfind(\".\")\n    if last_full_stop != -1:\n        return truncated_text[:last_full_stop + 1]  # Include the full stop\n    else:\n        return truncated_text  # No full stop found; return truncated text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:34:30.789104Z","iopub.execute_input":"2024-11-26T20:34:30.789916Z","iopub.status.idle":"2024-11-26T20:34:30.795052Z","shell.execute_reply.started":"2024-11-26T20:34:30.789880Z","shell.execute_reply":"2024-11-26T20:34:30.794307Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def inference(text, model, tokenizer, max_input_tokens=100, max_output_tokens=120):\n    # Set pad_token_id if not already set\n    if tokenizer.pad_token_id is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    # Tokenize\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=max_input_tokens,\n        padding=True  # Ensure padding is handled\n    )\n\n    # Generate\n    device = model.device\n    generated_tokens_with_prompt = model.generate(\n        input_ids=inputs['input_ids'].to(device),\n        attention_mask=inputs['attention_mask'].to(device),  # Include attention mask\n        max_length=max_output_tokens,\n        pad_token_id=tokenizer.pad_token_id  # Set pad_token_id\n    )\n\n    # Decode\n    generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n\n    # Strip the prompt\n    generated_text_answer = generated_text_with_prompt[0][len(text):]\n\n    truncated_text = truncate_to_nearest_sentence(generated_text_answer, max_output_tokens)\n\n    return generated_text_answer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:34:55.200118Z","iopub.execute_input":"2024-11-26T20:34:55.200469Z","iopub.status.idle":"2024-11-26T20:34:55.207663Z","shell.execute_reply.started":"2024-11-26T20:34:55.200438Z","shell.execute_reply":"2024-11-26T20:34:55.206793Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"test_text = test_dataset[125]['question']\nprint(\"Question input (test):\", test_text)\nprint(f\"Correct answer from dataset: {test_dataset[125]['answer']}\")\nprint(\"Model's answer: \")\nprint(inference(test_text, fine_tuned_model, fine_tuned_tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T17:39:57.162135Z","iopub.execute_input":"2024-11-26T17:39:57.162943Z","iopub.status.idle":"2024-11-26T17:39:59.050505Z","shell.execute_reply.started":"2024-11-26T17:39:57.162912Z","shell.execute_reply":"2024-11-26T17:39:59.049631Z"}},"outputs":[{"name":"stdout","text":"Question input (test): I'm having trouble coping with the recent death of a loved one. What can I do to start moving on?\nCorrect answer from dataset: Grieving is a difficult and individual process. It's important to give yourself time and permission to feel all the emotions that come with loss. Seek support from friends or a therapist, who can offer understanding and guidance. Join a grief support group to connect with others who have experienced similar loss. Try to maintain healthy habits, such as exercise and a balanced diet. Finally, find ways to honor and remember your loved one, such as creating a memorial or doing something in their memory.\nModel's answer: \nGrief is a natural and normal process, and it's important to allow yourself to feel your emotions. We can work on developing coping strategies, such as talking about your feelings or engaging in self-care activities, to help you process your grief and move on. It's also important to give yourself time to grieve and process your emotions. Remember that everyone grieves differently and it's okay to take things one day at a time. If you're having trouble moving on,\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"untrained_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")\nuntrained_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:35:18.978259Z","iopub.execute_input":"2024-11-26T20:35:18.979045Z","iopub.status.idle":"2024-11-26T20:35:34.377687Z","shell.execute_reply.started":"2024-11-26T20:35:18.979012Z","shell.execute_reply":"2024-11-26T20:35:34.376946Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"untrained_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:35:45.025862Z","iopub.execute_input":"2024-11-26T20:35:45.026788Z","iopub.status.idle":"2024-11-26T20:35:46.521933Z","shell.execute_reply.started":"2024-11-26T20:35:45.026751Z","shell.execute_reply":"2024-11-26T20:35:46.520981Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 2048)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"test_text = test_dataset[100]['question']\nprint(\"Question input (test):\", test_text)\nprint(f\"Correct answer from dataset: {test_dataset[100]['answer']}\")\nprint(\"Pre-trained Model's answer: \")\nprint(inference(test_text, untrained_model, untrained_tokenizer))\nprint(\"Fine-tuned Model's answer: \")\nprint(inference(test_text, fine_tuned_model, fine_tuned_tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T17:47:20.883415Z","iopub.execute_input":"2024-11-26T17:47:20.884053Z","iopub.status.idle":"2024-11-26T17:47:24.847132Z","shell.execute_reply.started":"2024-11-26T17:47:20.884002Z","shell.execute_reply":"2024-11-26T17:47:24.846270Z"}},"outputs":[{"name":"stdout","text":"Question input (test): I'm having trouble adjusting to a new job. What can I do to cope with the transition?\nCorrect answer from dataset: Transitions can be difficult, but it's important to give yourself time to adjust and process your emotions. Seeking support from coworkers, setting realistic expectations, and practicing self-care can also be helpful. Let's work together to develop a personalized plan to cope with your transition.\nPre-trained Model's answer: \n I'm having trouble adjusting to a new job. What can I do to cope with the transition?\nI'm having trouble adjusting to a new job. What can I do to cope with the transition?\nI'm having trouble adjusting to a new job. What can I do to cope with the transition?\nI'm having trouble adjusting to a new job. What can I do to cope with the transition?\nI'm having trouble adjusting to a new job. What can I do to cope with the transition\nFine-tuned Model's answer: \nIt's important to give yourself time to adjust to your new job and learn how to cope with the changes. Let's work together to identify any challenges you're facing and develop strategies to improve your performance and reduce stress. We can also explore any underlying issues that may be contributing to your difficulty adjusting. Would you like to start by discussing what specifically is causing you difficulty? Then we can work together to develop strategies to improve your performance and reduce stress. It's important to remember that adjusting to a\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"questions=[]\nanswers=[]\npretrained_responses=[]\nfinetuned_responses=[]\n\nfor i in range(50):\n    test_text = test_dataset[i]['question']\n    test_answer = test_dataset[i]['answer']\n    pretrained_ans = inference(test_text, untrained_model, untrained_tokenizer)\n    finetuned_ans = inference(test_text, fine_tuned_model, fine_tuned_tokenizer)\n    questions.append(test_text)\n    answers.append(test_answer)\n    pretrained_responses.append(pretrained_ans)\n    finetuned_responses.append(finetuned_ans)\n\ndf = pd.DataFrame({\n    \"Question\": questions,\n    \"Pretrained Model Response\": pretrained_responses,\n    \"Fine-tuned Model Response\": finetuned_responses,\n    \"Dataset Answer\": answers\n})    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:38:26.509048Z","iopub.execute_input":"2024-11-26T20:38:26.509410Z","iopub.status.idle":"2024-11-26T20:41:26.731383Z","shell.execute_reply.started":"2024-11-26T20:38:26.509378Z","shell.execute_reply":"2024-11-26T20:41:26.730417Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:37:24.981342Z","iopub.execute_input":"2024-11-26T20:37:24.981718Z","iopub.status.idle":"2024-11-26T20:37:24.992381Z","shell.execute_reply.started":"2024-11-26T20:37:24.981683Z","shell.execute_reply":"2024-11-26T20:37:24.991532Z"}},"outputs":[{"name":"stdout","text":"                                            Question  \\\n0  I think I might have depression. What should I...   \n1  I've gone to a couple therapy sessions so far ...   \n2  I'm feeling really anxious about public speaki...   \n3  My best friend and I were pranking her friend,...   \n4  I'm feeling really stressed out at work. What ...   \n\n                           Pretrained Model Response  \\\n0   What can I do to help myself?\\nYou’re not alo...   \n1   Is there anything I can do to help myself fee...   \n2   I'm not a public speaker at all. I'm just a m...   \n3   What should I do?\\nYour best friend and I wer...   \n4   I'm feeling really stressed out at work. What...   \n\n                           Fine-tuned Model Response  \\\n0  It's important to take your symptoms seriously...   \n1  Therapy is a safe place to explore feelings an...   \n2  It's normal to feel anxious before speaking in...   \n3   What can I do?I'm sorry for your hurt feeling...   \n4  It's important to take breaks throughout the d...   \n\n                                      Dataset Answer  \n0  It's important to seek professional help if yo...  \n1  Everyone has different experiences going to th...  \n2  Let's work on building your confidence and dev...  \n3  This takes time. I don't know how long it has ...  \n4  Let's work together to identify the sources of...  \n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"df.to_csv(\"./kaggle/working/LLM_Mental_Health/llama-3.2-1b-mental-health/finaltrainedv1/responses_comparison.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:50:31.353369Z","iopub.execute_input":"2024-11-26T20:50:31.354070Z","iopub.status.idle":"2024-11-26T20:50:31.364911Z","shell.execute_reply.started":"2024-11-26T20:50:31.354036Z","shell.execute_reply":"2024-11-26T20:50:31.364125Z"}},"outputs":[],"execution_count":29}]}